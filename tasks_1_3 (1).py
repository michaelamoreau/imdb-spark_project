# -*- coding: utf-8 -*-
"""Tasks 1-3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hUXby8hUTo-o8e7VCO9sxw7QvSpTubnR
"""

!pip install pyspark

from pyspark import SparkConf
from pyspark.sql import SparkSession
import pyspark.sql.types  as t
import pyspark.sql.functions as f
from google.colab import drive 
drive.mount('/content/drive')

import pyspark.sql.types as t

spark = SparkSession.builder.getOrCreate()

title_akas = spark.read.text("/content/drive/MyDrive/title.akas.tsv.gz")
name_basics = spark.read.text("/content/drive/MyDrive/name.basics.tsv.gz")

def task1(input):
    df = input.filter(input.value.contains("UA"))
    df = df.select(f.split(df.value, '\t').alias('value'))
    df = df.select(df.value.getItem(100).alias('value'))
    df = df.withColumn("value", f.concat_ws(" ",f.col("value")))
    df.write.csv("/content/drive/MyDrive/result1.csv")
    
df = spark.read.option('title', 'name').csv('/content/drive/MyDrive/result1.csv')
df.show(1000000000)

title_akas = spark.read.text("/content/drive/MyDrive/title.akas.tsv.gz")
name_basics = spark.read.text("/content/drive/MyDrive/name.basics.tsv.gz")
def task2(input):
    df = input.select(f.split(input.value, '\t').alias('value'))
    df = df.filter((df.value[1] > 1801) & (df.vale[2] < 1900))
    df = df.select(df.value.getItem(1).alias('value'))
    df.write.csv("/content/drive/MyDrive/result2.csv")
df = spark.read.csv(['/content/drive/MyDrive/result2.csv'])
df.show(1000000000)

def task3(input):
    df = input.select(f.split(input.value, '\t').alias('value'))
    df = df.filter((df.value[7] > 120) & (df.value[1] == "movie"))
    df = df.select(df.value.getItem(2).alias('value'))
    df.write.csv("/content/drive/MyDrive/result3.csv")
    df = spark.read.csv(['/content/drive/MyDrive/result3.csv'])

df.show(1000000000)

